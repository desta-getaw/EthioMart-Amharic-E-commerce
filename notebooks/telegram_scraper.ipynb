{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73e7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.errors.rpcerrorlist import ChannelInvalidError, ChannelPrivateError\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow running asyncio event loops within a Jupyter notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6a0bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading credentials from .env file...\n",
      "Credentials loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading credentials from .env file...\")\n",
    "load_dotenv()\n",
    "\n",
    "# Get credentials securely from the environment\n",
    "api_id = os.getenv(\"API_ID\")\n",
    "api_hash = os.getenv(\"API_HASH\")\n",
    "phone = os.getenv(\"PHONE_NUMBER\")\n",
    "\n",
    "# Check if the variables were loaded correctly\n",
    "if not all([api_id, api_hash, phone]):\n",
    "    raise ValueError(\"API_ID, API_HASH, or PHONE_NUMBER not found. Make sure you have a .env file in the project root with the correct values.\")\n",
    "\n",
    "print(\"Credentials loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27a7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_scrape = [\n",
    "    'ZemenExpress',\n",
    "    'nevacomputer',\n",
    "    'qnashcom',\n",
    "    'helloomarketethiopia',\n",
    "    'modernshoppingcenter'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd920c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_messages(client, channel_identifier, limit=300):\n",
    "    \"\"\"\n",
    "    Asynchronously fetches message history from a single Telegram channel using its ID or username.\n",
    "    \"\"\"\n",
    "    all_messages = []\n",
    "    channel_name_for_print = str(channel_identifier) # Default name for logging\n",
    "\n",
    "    try:\n",
    "        # This works whether you provide a username or an integer ID\n",
    "        channel_entity = await client.get_entity(channel_identifier)\n",
    "        channel_name_for_print = getattr(channel_entity, 'username', str(channel_identifier))\n",
    "        \n",
    "        async for message in client.iter_messages(channel_entity, limit=limit):\n",
    "            # We only care about messages with text content\n",
    "            if message.text:\n",
    "                all_messages.append({\n",
    "                    'channel_name': getattr(channel_entity, 'username', str(channel_identifier)),\n",
    "                    'message_id': message.id,\n",
    "                    'timestamp': message.date,\n",
    "                    'text_original': message.text,\n",
    "                    'views': message.views if message.views else 0,\n",
    "                    'has_image': message.photo is not None\n",
    "                })\n",
    "        \n",
    "        print(f\"Successfully scraped {len(all_messages)} messages from @{channel_name_for_print}.\")\n",
    "        return all_messages\n",
    "\n",
    "    except (ChannelInvalidError, ValueError):\n",
    "        print(f\"Error: Channel '@{channel_name_for_print}' not found or is invalid. Skipping.\")\n",
    "        return []\n",
    "    except ChannelPrivateError:\n",
    "        print(f\"Error: Channel '@{channel_name_for_print}' is private. You must join it first. Skipping.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with @{channel_name_for_print}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e246d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main function to coordinate the scraping process.\"\"\"\n",
    "    all_scraped_data = []\n",
    "    \n",
    "    # The 'async with' block handles connecting and disconnecting automatically\n",
    "    # The session file will be created in the root directory.\n",
    "    async with TelegramClient('session_name', api_id, api_hash) as client:\n",
    "        print(\"Client created successfully. Starting to scrape channels...\")\n",
    "        for channel in channels_to_scrape:\n",
    "            print(f\"--- Processing channel: {channel} ---\")\n",
    "            channel_data = await fetch_messages(client, channel, limit=300) # Fetch up to 300 messages per channel\n",
    "            all_scraped_data.extend(channel_data)\n",
    "\n",
    "    if not all_scraped_data:\n",
    "        print(\"\\nScraping finished, but no data was collected. Please check your channel IDs/usernames and network.\")\n",
    "        return pd.DataFrame() # Return an empty dataframe\n",
    "    \n",
    "    df = pd.DataFrame(all_scraped_data)\n",
    "    \n",
    "    # Save the raw scraped data before any cleaning\n",
    "    df.to_csv('../data/scraped_data.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nScraping complete. Collected a total of {len(df)} messages.\")\n",
    "    print(\"Raw data saved to 'data/scraped_data.csv'\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b89d8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the scraping process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempt 1 at connecting failed: TimeoutError: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in successfully as Desta Getaw; remember to not break the ToS or you will risk an account ban!\n",
      "Client created successfully. Starting to scrape channels...\n",
      "--- Processing channel: ZemenExpress ---\n",
      "Successfully scraped 117 messages from @ZemenExpress.\n",
      "--- Processing channel: nevacomputer ---\n",
      "Successfully scraped 92 messages from @nevacomputer.\n",
      "--- Processing channel: qnashcom ---\n",
      "Successfully scraped 231 messages from @qnashcom.\n",
      "--- Processing channel: helloomarketethiopia ---\n",
      "Successfully scraped 276 messages from @helloomarketethiopia.\n",
      "--- Processing channel: modernshoppingcenter ---\n",
      "Successfully scraped 80 messages from @modernshoppingcenter.\n",
      "\n",
      "Scraping complete. Collected a total of 796 messages.\n",
      "Raw data saved to 'data/scraped_data.csv'\n",
      "\n",
      "--- Starting Data Preprocessing ---\n",
      "Cleaning text data...\n",
      "Preprocessing complete. Cleaned data saved to 'data/preprocessed_data.csv'\n",
      "\n",
      "--- Preprocessed DataFrame Sample ---\n",
      "Top 5 rows:\n",
      "   channel_name                                       text_cleaned  views\n",
      "0  ZemenExpress  ................................... Saachi Ele...   1254\n",
      "1  ZemenExpress  ................................... 3pcs Bottl...   2091\n",
      "2  ZemenExpress  ................................... 3pcs Bottl...   1757\n",
      "3  ZemenExpress  ................................... 1 pairs Sn...   1951\n",
      "4  ZemenExpress  ................................... 1 pairs Sn...   2086\n",
      "\n",
      "Random 5 rows:\n",
      "             channel_name                                       text_cleaned  \\\n",
      "98           ZemenExpress  ................................... 12pcs Sili...   \n",
      "499  helloomarketethiopia  ለፀጉሮ ውበት እና ለፀጉሮዎ ልስላሴ ሰን ሲልክ የፀጉር ሻምፖ ለማዘዝ 09...   \n",
      "300              qnashcom  📣 Sealed Grain and Flour Storage Box ` የሽሮና የበ...   \n",
      "673  helloomarketethiopia  ኤሌክትሮኒክ አልትራሳውንድ ተባይ ማጥፊያ ለማዘዝ 0974312223 ይደውሉ...   \n",
      "462  helloomarketethiopia    ይጠቀማሉ ብለው ለምታስቧቸው አሁኑኑ ላኩላቸው! 🎉 ሶስት ቀናት ብቻ ቀሩት!   \n",
      "\n",
      "     views  \n",
      "98    4500  \n",
      "499   3562  \n",
      "300   9218  \n",
      "673   3716  \n",
      "462   2516  \n",
      "\n",
      "Last 5 rows:\n",
      "             channel_name                                       text_cleaned  \\\n",
      "791  modernshoppingcenter  **ቴሌግራም****🫐**** ** \"በአዲስ ነገረ ሁሌም ቀዳሚዏች ነን\" **...   \n",
      "792  modernshoppingcenter  **ቴሌግራም****⭐**** **** \"በአዲስ ነገር ሁሌም ቀዳሚዎች ነን\" ...   \n",
      "793  modernshoppingcenter  **ቴሌግራም****⭐**** **** \"በአዲስ ነገረ ሁሌም ቀዳሚዏች ነን\" ...   \n",
      "794  modernshoppingcenter  **ቴሌግራም****🍀**** **** \"በአዲስ ነገረ ሁሌም ቀዳሚዏች ነን\" ...   \n",
      "795  modernshoppingcenter  **ቴሌግራም****🍀**** **** \"በአዲስ ነገረ ሁሌም ቀዳሚዏች ነን\" ...   \n",
      "\n",
      "     views  \n",
      "791  16080  \n",
      "792  14660  \n",
      "793  15944  \n",
      "794  16286  \n",
      "795  16081  \n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Run the Scraper ---\n",
    "print(\"Starting the scraping process...\")\n",
    "# Note: The first time you run this, Telethon will ask for your phone number,\n",
    "# a login code sent to your Telegram app, and possibly your 2FA password.\n",
    "df_scraped = asyncio.run(main())\n",
    "\n",
    "if not df_scraped.empty:\n",
    "    print(\"\\n--- Starting Data Preprocessing ---\")\n",
    "\n",
    "    def clean_text(text):\n",
    "        \"\"\"A function to clean Amharic text for NER.\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Remove URLs and Telegram links\n",
    "        text = re.sub(r'http\\S+|www\\S+|t\\.me/\\S+', '', text, flags=re.MULTILINE)\n",
    "        # Remove user mentions and hashtags\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "        # Remove specific decorative characters and common emojis\n",
    "        text = re.sub(r'[💥📌💵✅👉📍📞☎️👇✨✔®©™❤🔥]', '', text)\n",
    "        # Replace multiple newlines/whitespace with a single space\n",
    "        text = re.sub(r'[\\n\\r\\s]+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    print(\"Cleaning text data...\")\n",
    "    df_scraped['text_cleaned'] = df_scraped['text_original'].apply(clean_text)\n",
    "    \n",
    "    # Save the final preprocessed data\n",
    "    df_scraped.to_csv('../data/preprocessed_data.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"Preprocessing complete. Cleaned data saved to 'data/preprocessed_data.csv'\")\n",
    "    \n",
    "    print(\"\\n--- Preprocessed DataFrame Sample ---\")\n",
    "    # Display a sample from different parts of the dataframe to see the variety\n",
    "    print(\"Top 5 rows:\")\n",
    "    print(df_scraped[['channel_name', 'text_cleaned', 'views']].head())\n",
    "    print(\"\\nRandom 5 rows:\")\n",
    "    print(df_scraped[['channel_name', 'text_cleaned', 'views']].sample(5))\n",
    "    print(\"\\nLast 5 rows:\")\n",
    "    print(df_scraped[['channel_name', 'text_cleaned', 'views']].tail())\n",
    "else:\n",
    "    print(\"\\nSkipping preprocessing because no data was scraped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".desvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
